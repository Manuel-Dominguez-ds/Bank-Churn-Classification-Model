{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score,precision_score,accuracy_score,recall_score,classification_report,confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV, KFold, RandomizedSearchCV,RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,MinMaxScaler,LabelEncoder,Normalizer,MaxAbsScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "#from imblearn.combine import SMOTEENN\n",
    "from feature_engine.encoding import CountFrequencyEncoder,OrdinalEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import pickle\n",
    "from datetime import date\n",
    "import datetime\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_group_by_exit(df,var):\n",
    "    plt.figure(figsize=(16, 6))\n",
    "\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    ax2 = plt.subplot(1, 2, 2)\n",
    "\n",
    "    sns.histplot(df[df['Exited'] == 1][var], ax=ax1, color='salmon', alpha=0.7)\n",
    "    sns.histplot(df[df['Exited'] == 0][var], ax=ax2, color='steelblue', alpha=0.7)\n",
    "\n",
    "    ax1.set_title(f'Distribución de {var} en Clientes que Hicieron Churn')\n",
    "    ax1.set_xlabel(var)\n",
    "    ax1.set_ylabel('Cantidad')\n",
    "\n",
    "    ax2.set_title(f'Distribución de {var} en Clientes Retenidos')\n",
    "    ax2.set_xlabel(var)\n",
    "    ax2.set_ylabel('Cantidad')\n",
    "\n",
    "    ax1.legend(['Churned'], loc='upper right')\n",
    "    ax2.legend(['Not churned'], loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def boxplot_by_exit(df,var):\n",
    "    plt.figure(figsize=(16, 6))\n",
    "\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    ax2 = plt.subplot(1, 2, 2)\n",
    "\n",
    "    sns.boxplot(y=var,data=df[df['Exited'] == 1], ax=ax1, color='salmon')\n",
    "    sns.boxplot(y=var,data=df[df['Exited'] == 0], ax=ax2, color='steelblue')\n",
    "\n",
    "    ax1.set_title(f'Boxplot de {var} en Clientes que Hicieron Churn')\n",
    "    ax1.set_xlabel(var)\n",
    "    ax1.set_ylabel('Cantidad')\n",
    "\n",
    "    ax2.set_title(f'Boxplot de {var} en Clientes Retenidos')\n",
    "    ax2.set_xlabel(var)\n",
    "    ax2.set_ylabel('Cantidad')\n",
    "\n",
    "    ax1.legend(['Churned'], loc='upper right')\n",
    "    ax2.legend(['Not churned'], loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def new_variables(df):\n",
    "  df['CreditScore_x_Age']=df['CreditScore']/df['Age']\n",
    "  df['CreditScore_x_Balance']=df['Balance']/df['CreditScore']\n",
    "  df['NumOfProducts_x_Age']=df['NumOfProducts']/df['Age']\n",
    "  df['Tenure_x_Age']=df.apply(lambda x: x['Tenure']/x['Age'] if x['Age']!=None else 0,axis=1)\n",
    "  df['%SalaryInBank']=(df['Tenure']*df['Balance'])/df['EstimatedSalary']\n",
    "  df['Balance_x_EstimatedSalary']=df['Balance']/df['EstimatedSalary']\n",
    "  df['AgeofEntry']=df['Age']-df['Tenure']\n",
    "  df['CustomerEngagement']=df.apply(lambda x:x['Age']*x['CreditScore']*x['NumOfProducts'],axis=1)\n",
    "  df['EducationProduct']=df.apply(lambda x:x['Age']*x['EducationYears']*x['NumOfProducts'],axis=1)\n",
    "\n",
    "  return df\n",
    "\n",
    "def encoding(df):\n",
    "  df=pd.get_dummies(data=df,columns=['Geography'])\n",
    "  return df\n",
    "\n",
    "def imputer(df,cat_imputer,num_imputer,train=True):\n",
    "  cat=[]\n",
    "  num=[]\n",
    "  if 'Id' in df.columns:\n",
    "    df=df.drop('Id',axis=1)\n",
    "  else:\n",
    "    pass\n",
    "  if 'Exited' in df.columns:\n",
    "    for col in df.drop('Exited',axis=1).columns:\n",
    "      if df[col].dtype=='object':\n",
    "        cat.append(col)\n",
    "      else:\n",
    "        num.append(col)\n",
    "    if train==True:\n",
    "      df[cat]=cat_imputer.fit_transform(df[cat])\n",
    "      df[num]=num_imputer.fit_transform(df[num])\n",
    "    else:\n",
    "      df[cat]=cat_imputer.transform(df[cat])\n",
    "      df[num]=num_imputer.transform(df[num])\n",
    "    return df\n",
    "  else:\n",
    "    for col in df.columns:\n",
    "      if df[col].dtype=='object':\n",
    "        cat.append(col)\n",
    "      else:\n",
    "        num.append(col)\n",
    "    if train==True:\n",
    "      df[cat]=cat_imputer.fit_transform(df[cat])\n",
    "      df[num]=num_imputer.fit_transform(df[num])\n",
    "    else:\n",
    "      df[cat]=cat_imputer.transform(df[cat])\n",
    "      df[num]=num_imputer.transform(df[num])\n",
    "    return df\n",
    "\n",
    "def print_metrics(y_val, y_pred,clf,X_val,skf):\n",
    "  precision, recall, thresholds = precision_recall_curve(y_val, y_pred)\n",
    "  pr_auc = auc(recall, precision)\n",
    "  accuracy = accuracy_score(y_val, y_pred)\n",
    "  precision=precision_score(y_val,y_pred)\n",
    "  recall=recall_score(y_val,y_pred)\n",
    "  f1=f1_score(y_val,y_pred)\n",
    "  auc_score = roc_auc_score(y_val, y_pred)\n",
    "  report = classification_report(y_val, y_pred)\n",
    "  print(f\"Accuracy: {accuracy}\")\n",
    "  print(f\"Precision: {precision}\")\n",
    "  print(f\"Recall: {recall}\")\n",
    "  print(f\"F1-Score: {f1}\")\n",
    "  print(f\"AUC-Score: {auc_score}\")\n",
    "  print(f\"PRAUC: {pr_auc:.4f}\")\n",
    "  print(f\"Cross-Validation Accuracy: {cross_val_score(clf,X_val,y_val,cv=skf,scoring='accuracy').mean()}\")\n",
    "  print(f\"Classification Report:\\n{report}\")\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "  sns.heatmap(confusion_matrix(y_true, y_pred),\n",
    "              annot=True,\n",
    "              fmt='g',\n",
    "              xticklabels=['0', '1'],\n",
    "              yticklabels=['0', '1'])\n",
    "  plt.ylabel('Actual', fontsize=13)\n",
    "  plt.xlabel('Prediction', fontsize=13)\n",
    "  plt.title('Confusion Matrix', fontsize=17)\n",
    "  plt.show()\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred):\n",
    "  fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "  roc_auc = auc(fpr, tpr)\n",
    "  plt.figure(figsize=(8, 6))\n",
    "  plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "  plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "  plt.xlabel('False Positive Rate')\n",
    "  plt.ylabel('True Positive Rate')\n",
    "  plt.title('ROC Curve')\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.show()\n",
    "\n",
    "def plot_learning_curve(model, X, y,skf):\n",
    "  train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=skf, scoring='accuracy', train_sizes=np.linspace(0.1, 1.0, 5))\n",
    "  \n",
    "  train_scores_mean = np.mean(train_scores, axis=1)\n",
    "  train_scores_std = np.std(train_scores, axis=1)\n",
    "  test_scores_mean = np.mean(test_scores, axis=1)\n",
    "  test_scores_std = np.std(test_scores, axis=1)\n",
    "  \n",
    "  plt.title(\"Learning Curve\")\n",
    "  plt.xlabel(\"Training examples\")\n",
    "  plt.ylabel(\"Score\")\n",
    "  \n",
    "  plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "  plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "  \n",
    "  plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "  plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "  \n",
    "  plt.legend(loc=\"best\")\n",
    "  plt.grid()\n",
    "    \n",
    "def plot_precision_recall_curve(y_true, y_pred):\n",
    "  precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "  average_precision = average_precision_score(y_true, y_pred)\n",
    "  \n",
    "  plt.figure(figsize=(8, 6))\n",
    "  plt.plot(recall, precision, marker='.', label=f'AP={average_precision:.2f}')\n",
    "  plt.xlabel('Recall')\n",
    "  plt.ylabel('Precision')\n",
    "  plt.title('Precision-Recall Curve')\n",
    "  plt.legend()\n",
    "  plt.grid()\n",
    "  plt.show()\n",
    "    \n",
    "    \n",
    "def plot_calibration_curve(y_true, y_pred, n_bins=10):\n",
    "  prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=n_bins)\n",
    "  \n",
    "  plt.figure(figsize=(8, 6))\n",
    "  plt.plot(prob_pred, prob_true, marker='o', label='Calibration Curve')\n",
    "  plt.plot([0, 1], [0, 1], linestyle='--', label='Calibrated')\n",
    "  plt.xlabel('Mean Predicted Probability')\n",
    "  plt.ylabel('Fraction of Positives')\n",
    "  plt.title('Calibration Curve')\n",
    "  plt.legend()\n",
    "  plt.grid()\n",
    "  plt.show()\n",
    "    \n",
    "def plot_feature_importances(clf, X):\n",
    "  importances = clf.feature_importances_\n",
    "\n",
    "  # Sort importances in descending order\n",
    "  indices = np.argsort(importances)[::-1]\n",
    "\n",
    "  feature_names = X.columns[indices]\n",
    "\n",
    "  plt.figure(figsize=(12, 8))\n",
    "  plt.title(\"Feature Importances\")\n",
    "  plt.bar(range(len(indices)), importances[indices], color=\"b\", align=\"center\")\n",
    "  plt.xticks(range(len(indices)), feature_names, rotation=90)\n",
    "  plt.xlabel(\"Feature\")\n",
    "  plt.ylabel(\"Importance\")\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "  \n",
    "def plot_metrics(y_true,y_pred,clf,X_val,X_train,skf):\n",
    "  plot_confusion_matrix(y_true,y_pred)\n",
    "  plot_roc_curve(y_true,y_pred)\n",
    "  plot_learning_curve(clf,X_val,y_true,skf)\n",
    "  plot_precision_recall_curve(y_true,y_pred)\n",
    "  plot_calibration_curve(y_true,y_pred)\n",
    "  plot_feature_importances(clf,X_val)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(bagging_fraction=0.6, bagging_freq=10, boosting_type='dart',\n",
      "               feature_freaction=0.8, lambda_l1=1, lambda_l2=1, max_depth=10,\n",
      "               metric='binary_logloss', min_data_in_leaf=20,\n",
      "               min_gain_to_split=0.1, num_leaves=20, objective='binary')\n",
      "StandardScaler()\n",
      "CountFrequencyEncoder(encoding_method='frequency', variables=['Geography'])\n",
      "CountFrequencyEncoder(encoding_method='frequency', variables=['Geography'])\n"
     ]
    }
   ],
   "source": [
    "with open('Pickle_ipynb/model_LGBM.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "    print(clf)\n",
    "    \n",
    "with open('Pickle_ipynb/scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "    print(scaler)\n",
    "\n",
    "with open('Pickle_ipynb/encoder.pkl', 'rb') as f:\n",
    "    encoder = pickle.load(f)\n",
    "    print(encoder)\n",
    "    \n",
    "with open('Pickle_ipynb/encoder2.pkl', 'rb') as f:\n",
    "    encoder2 = pickle.load(f)\n",
    "    print(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: feature_freaction\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.1, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    }
   ],
   "source": [
    "tests=pd.read_csv('base_val.csv')\n",
    "test=tests\n",
    "\n",
    "test=test.drop(['Id','Surname','Passport'],axis=1)\n",
    "\n",
    "# Feature Engineering\n",
    "test=new_variables(test)\n",
    "test=encoder.transform(test)\n",
    "test=encoder2.transform(test)\n",
    "test=encoding(test)\n",
    "test.drop('Gender',axis=1,inplace=True)\n",
    "test_columns=test.columns\n",
    "test_scaled=scaler.transform(test)\n",
    "test=pd.DataFrame(test_scaled,columns=test_columns)\n",
    "\n",
    "# Prediction\n",
    "y_pred = clf.predict_proba(test)[:, 1]\n",
    "y_pred = (y_pred > 0.49).astype(int)\n",
    "tests['Exited']=y_pred\n",
    "sample_data=tests[['Id','Exited']]\n",
    "\n",
    "# File\n",
    "filename = f'Predictions - {datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M_%S\")} - .csv'\n",
    "with open(filename, 'a', encoding='utf-8') as file:\n",
    "    file.write(\"ID,Predictions\\n\")\n",
    "    for i in range(sample_data.shape[0]):\n",
    "        text = str(sample_data.Id[i])\n",
    "        predictions = str(sample_data.Exited[i])\n",
    "        encoded_text = text.encode('utf-8', errors='ignore')\n",
    "        encoded_predictions = predictions.encode('utf-8', errors='ignore')\n",
    "        decoded_text = encoded_text.decode('utf-8')\n",
    "        decoded_predictions = encoded_predictions.decode('utf-8')\n",
    "\n",
    "        line = f\"{decoded_text},{decoded_predictions}\"\n",
    "        file.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
